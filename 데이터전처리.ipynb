{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b58554-2e1a-4f3d-8cb6-1697fce09f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (2.3.4)\n",
      "Requirement already satisfied: Scipy in /opt/conda/lib/python3.11/site-packages (1.16.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b3f5b4-6a57-4f76-a6da-f58ba6694f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.16.3)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c4cbb8-d0d2-4278-bb12-925a669544bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Using cached imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Using cached imbalanced_learn-0.14.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.25.2 in /opt/conda/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (2.3.4)\n",
      "Requirement already satisfied: scipy<2,>=1.11.4 in /opt/conda/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /opt/conda/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.7.2)\n",
      "Requirement already satisfied: joblib<2,>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
      "Using cached imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Using cached imbalanced_learn-0.14.0-py3-none-any.whl (239 kB)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.14.0 imblearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b92460b-f381-44db-84bd-70965b83b49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "634a65de-16ba-4fd8-b2b2-f47bb495a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"./raw_total_data.csv\")\n",
    "df.describe().to_csv(\"raw_data_describe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80c2c591-a9db-48cf-9aa2-e7d0c1c25654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ==================== 1️⃣ 물리 파라미터 ====================\n",
    "class GeometryParams:\n",
    "    def __init__(self):\n",
    "        self.L_total = 47e-3\n",
    "        self.W_base = 20e-3\n",
    "        self.W_tongue = 12e-3\n",
    "        self.t = 1.6e-3\n",
    "        self.K_t_slot = 2.1\n",
    "        self.K_t_width = 1.2\n",
    "\n",
    "class MaterialProps:\n",
    "    def __init__(self):\n",
    "        self.E = 90e9\n",
    "        self.nu = 0.25\n",
    "        self.alpha_T = 8e-6\n",
    "        self.Ms = 250\n",
    "\n",
    "# ==================== 데이터 로드 ====================\n",
    "def load_data(raw_path=\"./raw_total_data.csv\", label_path=\"./label.xlsx\"):\n",
    "    df_raw = pd.read_csv(raw_path, encoding='utf-8')\n",
    "    df_label = pd.read_excel(label_path)\n",
    "    return df_raw, df_label\n",
    "\n",
    "# ==================== 컬럼명 표준화 ====================\n",
    "def standardize_columns(df):\n",
    "    mapping = {\n",
    "        '배정번호': 'batch_id',\n",
    "        '소입로 온도 4 Zone': 'T_soaking_4',\n",
    "        '솔트 컨베이어 온도 1 Zone': 'T_conveyor_1',\n",
    "        '솔트 컨베이어 온도 2 Zone': 'T_conveyor_2',\n",
    "        '솔트조 온도 1 Zone': 'T_salt_1',\n",
    "        '솔트조 온도 2 Zone': 'T_salt_2'\n",
    "    }\n",
    "    return df.rename(columns=mapping)\n",
    "\n",
    "# ==================== 배정번호별 피처 계산 ====================\n",
    "def aggregate_features(df, geo, mat):\n",
    "    feats = []\n",
    "    for bid, g in df.groupby('batch_id'):\n",
    "        if len(g) < 2:  # 너무 짧은 데이터는 제외\n",
    "            continue\n",
    "\n",
    "        feat = {'batch_id': bid}\n",
    "        T_soak = g['T_soaking_4'].mean()\n",
    "        T_salt = g[['T_salt_1', 'T_salt_2']].mean(axis=1).mean()\n",
    "        T_conv = g[['T_conveyor_1', 'T_conveyor_2']].mean(axis=1).mean()\n",
    "\n",
    "        # 온도 구배 계산\n",
    "        feat['gradient_to_salt_mean'] = T_soak - T_salt\n",
    "        feat['gradient_2nd_mean'] = T_salt - T_conv\n",
    "        feat['gradient_to_conv_mean'] = T_soak - T_conv\n",
    "        feat['T_salt_std'] = g[['T_salt_1','T_salt_2']].std(axis=1).mean()\n",
    "        feat['T_conv_std'] = g[['T_conveyor_1','T_conveyor_2']].std(axis=1).mean()\n",
    "        \n",
    "        # 열응력 추정\n",
    "        delta_T = feat['gradient_to_salt_mean']\n",
    "        sigma_base = mat.E * mat.alpha_T * delta_T / (1 - mat.nu)\n",
    "        feat['sigma_slot'] = sigma_base * geo.K_t_slot\n",
    "        feats.append(feat)\n",
    "\n",
    "    return pd.DataFrame(feats)\n",
    "\n",
    "# ==================== 라벨 처리 ====================\n",
    "def process_labels(df_label):\n",
    "    df = df_label.rename(columns={'배정번호':'batch_id','불량수량':'defect_count','양품수량':'normal_count'})\n",
    "    df['defect_count'] = df['defect_count'].fillna(0)\n",
    "    df['normal_count'] = df['normal_count'].fillna(0)\n",
    "    df['defect_rate'] = df['defect_count'] / (df['defect_count'] + df['normal_count'] + 1e-6)\n",
    "    return df[['batch_id','defect_rate']]\n",
    "\n",
    "# ==================== 이상치 제거 ====================\n",
    "def remove_outliers_iqr(df, cols, k=1.5):\n",
    "    df_clean = df.copy()\n",
    "    for col in cols:\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - k * iqr\n",
    "        upper = q3 + k * iqr\n",
    "        before = len(df_clean)\n",
    "        df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]\n",
    "        after = len(df_clean)\n",
    "        print(f\"  {col}: {before - after}개 이상치 제거 (남은 데이터 {after})\")\n",
    "    return df_clean\n",
    "\n",
    "# ==================== 스케일링 및 로그 변환 ====================\n",
    "def scale_and_log(df, feature_cols, target_col):\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[target_col] = np.log1p(df_scaled[target_col])  # 로그변환\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled[feature_cols] = scaler.fit_transform(df_scaled[feature_cols])\n",
    "    return df_scaled, scaler\n",
    "\n",
    "# ==================== 전체 파이프라인 ====================\n",
    "def preprocess_for_regression(raw_path=\"./raw_total_data.csv\", label_path=\"./label.xlsx\"):\n",
    "    geo, mat = GeometryParams(), MaterialProps()\n",
    "    df_raw, df_label = load_data(raw_path, label_path)\n",
    "    df_raw = standardize_columns(df_raw)\n",
    "    df_feat = aggregate_features(df_raw, geo, mat)\n",
    "    df_label = process_labels(df_label)\n",
    "\n",
    "    df = pd.merge(df_feat, df_label, on=\"batch_id\", how=\"inner\")\n",
    "\n",
    "    print(f\"\\n초기 데이터 개수: {len(df)}\")\n",
    "    df = remove_outliers_iqr(df, [\"gradient_to_salt_mean\", \"gradient_2nd_mean\", 'gradient_to_conv_mean', \"T_conv_std\",\"T_salt_std\"], k=1.5)\n",
    "    print(f\"이상치 제거 후: {len(df)}\")\n",
    "\n",
    "    features = [\"gradient_to_salt_mean\",\"gradient_2nd_mean\",'gradient_to_conv_mean',\"sigma_slot\",\"T_salt_std\",\"T_conv_std\"]\n",
    "    df_scaled, scaler = scale_and_log(df, features, \"defect_rate\")\n",
    "\n",
    "    df_scaled.to_csv(\"processed_regression_data.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    return df_scaled, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c32be62-58a2-4bda-9525-43e4006a9950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "초기 데이터 개수: 45\n",
      "  gradient_to_salt_mean: 11개 이상치 제거 (남은 데이터 34)\n",
      "  gradient_2nd_mean: 1개 이상치 제거 (남은 데이터 33)\n",
      "  gradient_to_conv_mean: 0개 이상치 제거 (남은 데이터 33)\n",
      "  T_conv_std: 4개 이상치 제거 (남은 데이터 29)\n",
      "  T_salt_std: 0개 이상치 제거 (남은 데이터 29)\n",
      "이상치 제거 후: 29\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df_ready, scaler = preprocess_for_regression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70aea408-1ea4-4002-94db-b74e690a26a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2445fa9a-edee-435a-b498-fc2e4d291da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "User defined (CPU)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
